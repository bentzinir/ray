maze_sac:
    env: maze
    run: SAC
    stop:
        episode_reward_mean: 5
        timesteps_total: 100000
    config:
        # Works for both torch and tf.
        framework: tf
        gamma: 0.99
        no_done_at_end: false
        target_network_update_freq: 1
        tau: 0.005
        # initial_alpha: 0.5
        train_batch_size: 32
        optimization:
            actor_learning_rate: 0.00025
            critic_learning_rate: 0.00025
            entropy_learning_rate: 0.00025
        learning_starts: 20000
        use_state_preprocessor: true
        Q_model:
          fcnet_activation: relu
          fcnet_hiddens: []
        policy_model:
          fcnet_activation: relu
          fcnet_hiddens: []
        metrics_smoothing_episodes: 20
        buffer_size: 400000
        model:
          conv_filters: [[32, [8, 8], 4], [64, [4, 4], 2], [64, [3, 3], 1], [1024, [7, 7], 1]]
          # conv_filters: [[16, [8, 8], 4], [32, [4, 4], 2], [256, [11, 11], 1]]
#        horizon: 10000
#        soft_horizon: true